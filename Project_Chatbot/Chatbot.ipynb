{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0f1bc0-d21b-435b-92f5-06e6364a66b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\etc\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\etc\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\etc\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\etc\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\etc\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\etc\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\skandr\n",
      "[nltk_data]     store\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\skandr\n",
      "[nltk_data]     store\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in c:\\etc\\lib\\site-packages (4.2.1)\n",
      "Requirement already satisfied: gensim in c:\\etc\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\etc\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\etc\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\etc\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\etc\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\etc\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\etc\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\etc\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\etc\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\etc\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\etc\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\etc\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\etc\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\etc\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\etc\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\etc\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\etc\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\etc\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: nltk in c:\\etc\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: langdetect in c:\\etc\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: sentence-transformers in c:\\etc\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: textdistance in c:\\etc\\lib\\site-packages (4.2.1)\n",
      "Requirement already satisfied: click in c:\\etc\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\etc\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\etc\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\etc\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: six in c:\\etc\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\etc\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\etc\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\etc\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\etc\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\etc\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\etc\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\etc\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\etc\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\etc\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\etc\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\etc\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\etc\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\etc\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\etc\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.data.path.append('C:\\\\Users\\\\skandr store\\\\AppData\\\\Roaming\\\\nltk_data\\\\tokenizers\\\\punkt')\n",
    "nltk.download('stopwords')\n",
    "!pip install textdistance\n",
    "import textdistance\n",
    "!pip install gensim\n",
    "!pip install sentence-transformers\n",
    "!pip install nltk langdetect sentence-transformers textdistance\n",
    "import re\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "188b9672-a9df-47b9-b53d-c4ba90cc0874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉‫ أهلاً وسهلاً بيك في شات بوت Event Ease!‬\n",
      "🎉 Welcome to the Event Ease Chatbot!\n",
      "📱 أنا هنا علشان أساعدك تخطط مناسبتك بسهولة – سواء فرح، خطوبة، عيد ميلاد أو غيرهم.\n",
      "📱 I'm here to help you easily plan your special events – weddings, engagements, birthdays, and more.\n",
      "💡 اسألني عن الحجز، الخدمات، تعديل أو إلغاء المناسبات، أو طريقة استخدام التطبيق.\n",
      "💡 Ask me about booking, services, editing or cancelling events, or how to use the app.\n",
      "🌐 تقدر تكتب بالعربي أو الإنجليزي.\n",
      "🌐 You can talk to me in Arabic or English.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "📨 اكتب سؤالك (أو 'خروج' / 'انهاء' / 'باي' للخروج)\n",
      "📨 Type your question (or 'exit' / 'bye' to quit):  عاوز احجز بدلة\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖: ‫📅 دي مهمة سهلة! اضغط 'Start Planning' واملا بيانات المناسبة‬.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "📨 اكتب سؤالك (أو 'خروج' / 'انهاء' / 'باي' للخروج)\n",
      "📨 Type your question (or 'exit' / 'bye' to quit):  عاوزة اغير الحجز\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖: ‫📌 للتحكم في الحجوزات (تعديل / إلغاء)، توجه لقسم 'My Events' واختر الإجراء المناسب ‬.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "📨 اكتب سؤالك (أو 'خروج' / 'انهاء' / 'باي' للخروج)\n",
      "📨 Type your question (or 'exit' / 'bye' to quit):  باي\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋‫ مع السلامة! شكرًا لاستخدامك شات بوت Event Ease ‬.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from gensim.models import Word2Vec\n",
    "from difflib import SequenceMatcher\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langdetect import detect\n",
    "\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "qa_pairs_ar = {\n",
    "    \"كيف أحجز مناسبة؟\":\n",
    "    \"\\u202B📅 اضغط على 'Start Planning' واملأ التفاصيل للحجز \\u202C.\",\n",
    "    \"أين أجد كل الايفينتات؟\": \n",
    "    \"\\u202B📋 من خلال الضغط على Events هتلاقي كل المناسبات اللي حضرتك سجلتها\\u202C.\",\n",
    "    \"كيف أضيف خدمات زي ميكب أو تصوير او بدلة؟\":\n",
    "    \"💄 بعد اختيار نوع المناسبة، هتقدر تختار الخدمات المطلوبة.\",\n",
    "    \"كيف أشغل الابلكيشن؟\": \n",
    "    \"\\u202B🔧 افتح التطبيق واضغط Start Planning وابدأ على طول\\u202C.\",\n",
    "    \"كيف أعدل أو ألغي الحجز ؟\": \n",
    "    \"\\u202B 📌 من My Events تقدر تعدل أو تلغي بسهولة \\u202C.\",\n",
    "    \"مش عارف أبدأ\":\n",
    "    \"\\u202B✨ مفيش مشكلة! اضغط Start Planning وامشي خطوة بخطوة\\u202C.\"}\n",
    "\n",
    "qa_pairs_en = {\n",
    "    \"How do I book an event?\": \"📅 Press 'Start Planning' and fill in the event details.\",\n",
    "    \"Where can I find my events?\": \"📋 Click on 'Events' to see all your booked events.\",\n",
    "    \"How do I add services like makeup or photography?\": \"💄 After selecting the event type, you can choose services like makeup or photography.\",\n",
    "    \"How to use the app?\": \"🔧 Open the app and click 'Start Planning' to begin.\",\n",
    "    \"How to cancel or edit a booking?\": \"📌 Go to 'My Events' to cancel or edit your booking.\",\n",
    "    \"I don't know how to start\": \"✨ No problem! Just click 'Start Planning' and follow the steps.\"}\n",
    "\n",
    "dialect_map_ar = {\n",
    "    \"ازاي\": \"كيف\",\n",
    "    \"ليه\": \"لماذا\",\n",
    "    \"ايه\": \"ما\",\n",
    "    \"عايز\": \"أريد\",\n",
    "    \"عاوزه\": \"أريد\",\n",
    "    \"احجز\": \"حجز\",\n",
    "    \"حجزت\": \"حجز\",\n",
    "    \"ايفينتس\": \"الايفينتس\",\n",
    "    \"ايفينت\": \"الايفينت\",\n",
    "    \"ألغى\": \"الغي\",\n",
    "    \"فين\": \"أين\",\n",
    "    \"إلغاء\": \"الغاء\"}\n",
    "\n",
    "dialect_map_en={\n",
    "    \"wya\": \"where are you\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"idk\": \"I don't know\"}\n",
    "\n",
    "keywords_groups_ar = {\n",
    "    \"استخدام\": [\"استخدم\", \"اشغل\",\"ابدأ\",\"التطبيق\",\"مشغل\",\"مش عارف اشغل\",\"مش عارفة\",\"مشكلة\",\"مشكله\", \"الابلكيشن\"],\n",
    "    \"حجز_مناسبة\": [\"احجز\",\"حجز\",\"مناسبة\", \"فرح\", \"حفلة\", \"تخرج\", \"عيدميلاد\",\"كتب كتاب\",\"خطوبة\",\"زفاف\",\"عيد ميلاد\",\"قاعة\",\"مؤتمرات\", \"حجز لمناسبة\"],\n",
    "    \"خدمات\": [\"فستان\", \"بيوتي سنتر\", \"حلاق\",\"بدلة\",\"بدله\", \"ميكب\", \"فوتوجرافر\",\"كوافيرة\",\"ضيف\",\"ضيوف\",\"فوتوغرافيا\",\"كوافير\",\"دعوة\",\"دعوات\",\"خدمة\",\"خدمات\",\"ميكب ارتيست\",\"البدلة\",\"دي جي\", \"تصوير\",\"حجز ميكب\", \"احجز ميكب\"],\n",
    "    \"الايفينتس\": [\"الايفينت\",\"الايفينتات\",\"قائمة\",\"المناسبات\",\"اللي فاتت\",\"سجلت\",\"مناسباتي\",\"معاد\",\"مواعيد\", \"events\", \"evt\"],\n",
    "    \"حجز_إداري\": [\"الغاء حجز\",\"الغي حجز\",\"اكد\",\"اعدل\",\"إلغاء\", \"ألغي\", \"الغاء\", \"ألغيه\", \"أعدل\", \"أعدله\", \"أعدلها\", \"ألغوها\", \"إلغاؤه\", \"إلغاءها\", \"إلغيه\", \"احذف\",\"تعديل\", \"عدلت\", \"أعدل\", \"غير\", \"غيّر\",\"احدث\",\"اغير\",\"تغيير\",\"شيل الحجز\",\"اشطب\",\"تحديث\",\"تعديل حجز\",\"الغي\", \"تم الحجز\", \"تأكيد الحجز\"]\n",
    "}\n",
    "\n",
    "keywords_groups_en = {\n",
    "    \"admin_booking\": [\"edit\",\"confirm\",\"confirm booking\",\"modify\",\"delete\",\"change\",\"update\",\"cancel\",\"done\"],\n",
    "    \"book_event\": [\"book event\",\"book\",\"venue\",\"birthday\", \"wedding\",\"party\",\"hall\",\"Conference\",\"Marriage\", \"graduation\", \"engagement\",\"create event\",\"reserve\",\"booking\",\"schedule\",\"register\"],\n",
    "    \"events\": [\"events\",\"my events\",\"registered\",\"events list\",\"list\",\"past\",\"date\",\"registered\",\"Occasions\",\"Dates\"],\n",
    "    \"services\": [\"makeup\", \"photography\", \"dress\",\"add\",\"Makeup Artist\",\"services\",\"Hairdresser\",\"Barber\",\"Invitation\",\"Invitations\",\"Guest\",\"Guests\",\"dj\",\"decoration\",\"service\",\"catering\", \"suit\", \"beauty center\", \"photographer\"],\n",
    "    \"usage\": [\"how to use\",\"app usage\",\"help\",\"use\",\"run\",\"application\",\"I don't know how to run\",\"Problem\",\"I don't know\",\"start\",\"app\",\"guide\",\"using the app\", \"how does it work\", \"open the app\"]\n",
    "}\n",
    "\n",
    "responses_ar = {\n",
    "    \"استخدام\": \"🤖 ماذا تريد أن تفعله لكي أساعدك؟\",\n",
    "    \"حجز_مناسبة\": \n",
    "    \"\\u202B📅 دي مهمة سهلة! اضغط 'Start Planning' واملا بيانات المناسبة\\u202C.\",\n",
    "    \"خدمات\": \n",
    "    \"\\u202B💄 احجز خدماتك بعد ملء تفاصيل المناسبة في 'Start Planning' \\u202C.\",\n",
    "    \"الايفينتس\":\n",
    "    \"\\u202B📋 تقدر تشوف كل الايفينتات من خلال الضغط على 'Events'\\u202C.\",\n",
    "    \"حجز_إداري\":\n",
    "    \"\\u202B📌 للتحكم في الحجوزات (تعديل / إلغاء)، توجه لقسم 'My Events' واختر الإجراء المناسب \\u202C.\"}\n",
    "\n",
    "responses_en = {\n",
    "    \"usage\": \"🔧 Open the app and click 'Start Planning' to begin.\",\n",
    "    \"book_event\": \"📅 Easy! Just click 'Start Planning' and fill in the event details.\",\n",
    "    \"services\": \"💄 After selecting your event, you can add services like makeup or photography.\",\n",
    "    \"events\": \"📋 You can view all your events by clicking on 'Events'.\",\n",
    "    \"admin_booking\": \"📌 To edit or cancel a booking, go to 'My Events' and choose the option you need.\"}\n",
    "\n",
    "abbreviations_map = {\n",
    "    \"evt\": \"الايفينت\",\n",
    "    \"evts\": \"الايفينتات\",\n",
    "    \"resv\": \"حجز\",\n",
    "    \"bday\": \"عيدميلاد\",\n",
    "    \"grad\": \"تخرج\",\n",
    "    \"app\": \"الابلكيشن\",\n",
    "    \"svc\": \"خدمات\",\n",
    "    \"mkp\": \"ميكب\",\n",
    "    \"ph\": \"فوتوجرافر\"}\n",
    "\n",
    "\n",
    "vectorizer_ar = TfidfVectorizer()\n",
    "question_vectors_ar = vectorizer_ar.fit_transform(list(qa_pairs_ar.keys()))\n",
    "vectorizer_en = TfidfVectorizer()\n",
    "question_vectors_en = vectorizer_en.fit_transform(list(qa_pairs_en.keys()))\n",
    "stopwords_ar = set(stopwords.words(\"arabic\"))\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "all_known_words = set()\n",
    "stemmer = ISRIStemmer()\n",
    "for group in list(keywords_groups_ar.values()) + list(keywords_groups_en.values()):\n",
    "    all_known_words.update(group)\n",
    "all_known_words.update(dialect_map_ar.keys())\n",
    "all_known_words.update(dialect_map_en.keys())\n",
    "all_known_words.update(abbreviations_map.keys())\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        arabic_chars = re.findall(r'[\\u0600-\\u06FF]', text)\n",
    "        arabic_ratio = len(arabic_chars) / max(len(text), 1)\n",
    "        if arabic_ratio > 0.3:\n",
    "            return 'ar'\n",
    "        language = detect(text)\n",
    "        return 'ar' if language == 'ar' else 'en'\n",
    "    except:\n",
    "        return 'en'\n",
    "        \n",
    "def normalize_dialect(text):\n",
    "    language = detect_language(text)\n",
    "    if language == \"ar\":\n",
    "        for word, replacement in dialect_map_ar.items():\n",
    "            text = text.replace(word, replacement)\n",
    "    elif language == \"en\":\n",
    "        for word, replacement in dialect_map_en.items():\n",
    "            text = text.replace(word, replacement)\n",
    "    return text\n",
    "\n",
    "def normalize_abbreviations(text):\n",
    "    for abbr, full in abbreviations_map.items():\n",
    "        text = text.replace(abbr, full)\n",
    "    return text\n",
    "\n",
    "def correct_word(word):\n",
    "    best_match = word\n",
    "    highest_score = 0\n",
    "    for known_word in all_known_words:\n",
    "        score = textdistance.jaro_winkler(word, known_word)\n",
    "        if score > highest_score and score > 0.85:\n",
    "            highest_score = score\n",
    "            best_match = known_word\n",
    "    return best_match\n",
    "      \n",
    "def correct_input_text(text):\n",
    "    words = text.split()\n",
    "    corrected_words = [correct_word(word) for word in words]\n",
    "    return \" \".join(corrected_words)   \n",
    "    \n",
    "def clean_input_keep_stopwords(user_input):\n",
    "    words = user_input.split()\n",
    "    keywords_in_input = []\n",
    "    for word in words:\n",
    "        if word not in stopwords_ar:\n",
    "            keywords_in_input.append(word)\n",
    "        else:\n",
    "            keywords_in_input.append(word)\n",
    "    return \" \".join(keywords_in_input)\n",
    "    \n",
    "def apply_stemming(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed)\n",
    "        \n",
    "def preprocess_text(text):\n",
    "    language=detect_language(text)\n",
    "    text = normalize_dialect(text)\n",
    "    text = normalize_abbreviations(text)\n",
    "    text = correct_input_text(text)\n",
    "    text = clean_input_keep_stopwords(text)\n",
    "    if language == \"ar\":\n",
    "        text = apply_stemming(text)\n",
    "    return text\n",
    "qa_pairs_ar = {preprocess_text(k): v for k, v in qa_pairs_ar.items()}\n",
    "questions_ar= list(qa_pairs_ar.keys())\n",
    "answers_ar = list(qa_pairs_ar.values())\n",
    "qa_pairs_en = {preprocess_text(k): v for k, v in qa_pairs_en.items()}\n",
    "questions_en = list(qa_pairs_en.keys())\n",
    "answers_en = list(qa_pairs_en.values())\n",
    "keywords_groups_ar = {\n",
    "    cat: [preprocess_text(p) for p in phrases]\n",
    "    for cat, phrases in keywords_groups_ar.items()}\n",
    "keywords_groups_en = {\n",
    "    cat: [preprocess_text(p) for p in phrases]\n",
    "    for cat, phrases in keywords_groups_en.items()}\n",
    "\n",
    "def smart_reply(user_input, language):\n",
    "    user_input_processed = preprocess_text(user_input)  \n",
    "    user_embedding = get_embedding(user_input)\n",
    "    if language == 'ar':\n",
    "        user_vector_ar = vectorizer_ar.transform([user_input_processed])\n",
    "        similarity_ar = cosine_similarity(user_vector_ar, question_vectors_ar)\n",
    "        max_sim_index_ar = similarity_ar.argmax()\n",
    "        max_sim_score_ar = similarity_ar[0, max_sim_index_ar]\n",
    "        if max_sim_score_ar > 0.3:\n",
    "            return answers_ar[max_sim_index_ar]\n",
    "    else:\n",
    "        lowered = user_input.lower()\n",
    "        if any(word in lowered for word in keywords_groups_en['usage']):\n",
    "            return responses_en[\"usage\"]\n",
    "        if any(word in lowered for word in keywords_groups_en['book_event']):\n",
    "            return responses_en[\"book_event\"]\n",
    "        if any(word in lowered for word in keywords_groups_en['admin_booking']):\n",
    "            return responses_en[\"admin_booking\"]\n",
    "        if any(word in lowered for word in keywords_groups_en['services']):\n",
    "            return responses_en[\"services\"]\n",
    "        if any(word in lowered for word in keywords_groups_en['events']):\n",
    "            return responses_en[\"events\"]\n",
    "        qa_embeddings = [get_embedding(q) for q in questions_en]\n",
    "        similarities = [get_similarity(user_embedding, emb) for emb in qa_embeddings]\n",
    "        max_sim_idx = max(range(len(similarities)), key=lambda i: similarities[i])\n",
    "        max_sim_score = similarities[max_sim_idx]\n",
    "        if max_sim_score > 0.65:\n",
    "            return answers_en[max_sim_idx]\n",
    "    return None\n",
    "        \n",
    "def split_long_phrase(text):\n",
    "    try:\n",
    "        return sent_tokenize(text)\n",
    "    except:\n",
    "        return [text]  \n",
    "\n",
    "def get_embedding(text):\n",
    "    return embedding_model.encode(text)\n",
    "\n",
    "def get_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    \n",
    "def is_sarcastic(text):\n",
    "    arabic_patterns = [\n",
    "        \"هو التطبيق بيشتغل\", \"يعني أضغط الزر\", \"بالنية\", \"زرار سحري\",\n",
    "        \"يشتغل لوحده\", \"كل حاجة تتحل\", \"بلمسة واحدة\", \"يا سلام\",\n",
    "        \"أكيد التطبيق\", \"أكيد دي\", \"بإذن الله التطبيق\",\"أكيد الابلكيشن\",\"بإذن الله الابلكيشن\", \"هو فين الزرار السحري\",\n",
    "        \"عايز معجزات\", \"آه طبعا\", \"عدم المساعدة\", \"واو\",\n",
    "        \"يا سلام على السهولة\"]\n",
    "    arabic_keywords = [\n",
    "        \"يا سلام\", \"زرار سحري\", \"واو\",\"لوحده\",\"الجنة\",\"النار\",\"القمر\",\"ياسلام\",\"زر\",\"زرار\",\"ساحر\",\"النية\", \"آه طبعا\", \"طبعا\"]\n",
    "    english_patterns = [\n",
    "        \"oh sure\", \"of course it works\", \"magic button\", \"just like that\", \"by itself\",\n",
    "        \"press a button and done\", \"god will do it\", \"it fixes everything\", \"wow so easy\",\n",
    "        \"clearly the app\", \"wow amazing\", \"i just click and magic happens\"]\n",
    "    english_keywords = [\n",
    "        \"oh sure\", \"wow\", \"magic\", \"obviously\",\"heaven\",\"hell\",\"magicain\",\"button\",\"moon\", \"right\", \"clearly\"]\n",
    "    text = text.lower()\n",
    "    for pattern in arabic_patterns + english_patterns:\n",
    "        if pattern in text:\n",
    "            return True\n",
    "    for word in arabic_keywords + english_keywords:\n",
    "        if word in text:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def detect_sarcasm(user_input):\n",
    "    if is_sarcastic(user_input):\n",
    "        language = detect_language(user_input)\n",
    "        if language == \"en\":\n",
    "            return \"😏 Sounds a bit sarcastic! Want real help with something?\"\n",
    "        else:\n",
    "            return \"😏 شكلك بتتكلم بسخرية! هل في حاجة أقدر أساعدك فيها فعلاً؟\"\n",
    "    return None \n",
    "    \n",
    "def detect_questions(user_input, language='ar'):\n",
    "    question_separators = ['؟','،', '?', 'و','ثم','كمان','برضو','كذلك','و كمان','و بعدين', 'and', 'also', 'as well', 'then']\n",
    "    segments = re.split('|'.join(map(re.escape, question_separators)), user_input)\n",
    "    segments = [s.strip() for s in segments if len(s.strip()) > 3]\n",
    "    return segments \n",
    "    \n",
    "def process_single_question(user_input):\n",
    "    user_input_norm = normalize_dialect(user_input)\n",
    "    language = detect_language(user_input)\n",
    "    if language not in [\"ar\", \"en\"]:\n",
    "        return \"عذرًا، لا أفهم هذه اللغة. أنا أفهم فقط العربية والإنجليزية.\\nSorry, I don't understand this language. I only understand Arabic and English.\"\n",
    "    if language==\"ar\":\n",
    "        user_input_norm = normalize_abbreviations(user_input_norm)\n",
    "        user_input_norm = correct_input_text(user_input_norm)\n",
    "        user_input_norm = clean_input_keep_stopwords(user_input_norm)\n",
    "        user_input_norm = apply_stemming(user_input_norm)\n",
    "        \n",
    "    sarcasm_response = detect_sarcasm(user_input)\n",
    "    if sarcasm_response:\n",
    "        return sarcasm_response    \n",
    "    thanks_keywords = [\"شكرا\", \"شكرًا\", \"متشكر\", \"thx\", \"thanks\", \"thank you\"]\n",
    "    if any(kw in user_input.lower() for kw in thanks_keywords):\n",
    "        return( \"🌟 العفو! سعيد بمساعدتك 😊\" if language == \"ar\" else \"🌟 You're welcome! Happy to help 😊\")\n",
    "    okay_keywords = [ \"اشطا\", \"تمام\", \"okay\"]\n",
    "    if any(kw in user_input.lower() for kw in okay_keywords):\n",
    "        return( \"🌟  سعيد بمساعدتك 😊\" if language == \"ar\" else \"🌟 Happy to help 😊\")\n",
    "    sentences=split_long_phrase(user_input_norm)\n",
    "    user_embedding = get_embedding(user_input_norm)\n",
    "    combined_keywords = {**keywords_groups_ar, **keywords_groups_en}\n",
    "    responses_dict = responses_ar if language == \"ar\" else responses_en\n",
    "    cancel_words = [\"الغاء\", \"الغي\",\"إلغاء\", \"ألغي\", \"ألغيه\", \"ألغوها\", \"إلغاؤه\", \"إلغاءها\", \"إلغيه\", \"ألغى\", \"احذف\", \"حذف\", \"remove\", \"cancel\", \"delete\"]\n",
    "    positive_words = [\"تأكيد الحجز\", \"تم الحجز\", \"confirmed\",\"confirm\", \"booked\"]  \n",
    "    is_cancel_request = any(word in user_input_norm for word in cancel_words) and not any(word in user_input_norm for word in positive_words)\n",
    "    if is_cancel_request:\n",
    "        cancel_targets = (\n",
    "            keywords_groups_ar[\"حجز_مناسبة\"] + keywords_groups_ar[\"خدمات\"] + keywords_groups_ar[\"الايفينتس\"]\n",
    "            if language == \"ar\"\n",
    "            else keywords_groups_en[\"book_event\"] + keywords_groups_en[\"services\"] + keywords_groups_en[\"events\"]\n",
    "        )\n",
    "        if any(t in user_input_norm for t in cancel_targets):\n",
    "            return responses_ar[\"حجز_إداري\"] if language == \"ar\" else responses_en[\"admin_booking\"]\n",
    "    editing_keywords =keywords_groups_en['admin_booking']+ keywords_groups_ar['حجز_إداري']\n",
    "    editing = any(word in user_input_norm for word in editing_keywords)\n",
    "    if editing :\n",
    "        return responses_en[\"admin_booking\"] if language == \"en\" else responses_ar[\"حجز_إداري\"]    \n",
    "    \n",
    "    def is_generic(response):\n",
    "        generic_keywords = [\"لمساعدتك\", \"أستطيع مساعدتك\", \"اسألني\", \"مساعد\", \"help\", \"assist\", \"anything else\"]\n",
    "        return any(kw in response.lower() for kw in generic_keywords)        \n",
    "    all_responses=[]    \n",
    "    seen_responses = set()\n",
    "    for sentence in sentences:\n",
    "        processed_sentence = preprocess_text(sentence)\n",
    "        smart=smart_reply(processed_sentence,language)\n",
    "        if smart and len(smart.split()) > 2 and not is_generic(smart):\n",
    "            if smart not in seen_responses:\n",
    "                all_responses.append(smart)\n",
    "                seen_responses.add(smart)    \n",
    "    if all_responses:\n",
    "        return \"\\n---\\n\".join(all_responses)        \n",
    "    tfidf_responses = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "        if language == 'ar':\n",
    "            sentence_vector_ar = vectorizer_ar.transform([sentence])\n",
    "            similarity_ar = cosine_similarity(sentence_vector_ar, question_vectors_ar)\n",
    "            max_sim_index_ar = similarity_ar.argmax()\n",
    "            max_sim_score_ar = similarity_ar[0, max_sim_index_ar]\n",
    "            if max_sim_score_ar > 0.4:\n",
    "                tfidf_responses.append(list(qa_pairs_ar.values())[max_sim_index_ar])\n",
    "        else:\n",
    "            sentence_vector_en = vectorizer_en.transform([sentence])\n",
    "            similarity_en = cosine_similarity(sentence_vector_en, question_vectors_en)\n",
    "            max_sim_index_en = similarity_en.argmax()\n",
    "            max_sim_score_en = similarity_en[0, max_sim_index_en] \n",
    "            if max_sim_score_en > 0.45 :\n",
    "                tfidf_responses.append(list(qa_pairs_en.values())[max_sim_index_en])\n",
    "    tfidf_responses = list(dict.fromkeys(tfidf_responses))  \n",
    "    tfidf_filtered = []\n",
    "    tfidf_embeddings = []\n",
    "    for r in tfidf_responses:\n",
    "        if is_generic(r.strip()):\n",
    "            continue\n",
    "        emb = get_embedding(r)\n",
    "        if any(cosine_similarity([emb], [prev])[0][0] > 0.87 for prev in tfidf_embeddings):\n",
    "            continue\n",
    "        tfidf_filtered.append((r, emb))\n",
    "        tfidf_embeddings.append(emb)\n",
    "    if tfidf_filtered:\n",
    "        tfidf_filtered.sort(key=lambda x: cosine_similarity([user_embedding], [x[1]])[0][0], reverse=True)\n",
    "        top_responses = [r for r, _ in tfidf_filtered[:3]]\n",
    "        for r in top_responses:\n",
    "            if r not in seen_responses:\n",
    "                all_responses.append(r)\n",
    "                seen_responses.add(r)\n",
    "        return \"\\n---\\n\".join(all_responses)\n",
    "        \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "        category_scores = {}\n",
    "        for category, phrases in combined_keywords.items():\n",
    "            matched_keywords = [phrase for phrase in phrases if phrase.lower() in sentence.lower()]\n",
    "            if matched_keywords:\n",
    "                priority_weight = 2 if category.lower() in [\"book_event\", \"events\", \"حجز_مناسبة\", \"الايفينتس\"] else 1\n",
    "                score = sum(2 if len(phrase.split()) > 1 else 1 for phrase in matched_keywords)\n",
    "                total_score = score * priority_weight\n",
    "                category_scores[category] = category_scores.get(category, 0) + total_score \n",
    "        if category_scores:\n",
    "            sorted_category = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            for category, score in sorted_category:\n",
    "                if category in [\"خدمات\", \"services\"]:\n",
    "                    stronger_categories = [cat for cat, s in sorted_category if s >= score and cat not in [\"خدمات\", \"services\"]]\n",
    "                    if stronger_categories:\n",
    "                        continue\n",
    "                if category in responses_dict:\n",
    "                    if responses_dict[category] not in seen_responses:\n",
    "                        all_responses.append(responses_dict[category])\n",
    "                        seen_responses.add(responses_dict[category])\n",
    "                    break \n",
    "    if all_responses:\n",
    "        return \"\\n---\\n\".join(all_responses)            \n",
    "    return \"🤔 مش فاهم عليك كويس، ممكن توضح أكتر؟\" if language == \"ar\" else \"🤔 I didn't quite understand. Could you clarify?\"\n",
    "    \n",
    "def get_response(user_input):\n",
    "    language = detect_language(user_input)\n",
    "    questions = detect_questions(user_input, language)\n",
    "\n",
    "    if len(questions) == 1:\n",
    "        return process_single_question(questions[0])\n",
    "    else:\n",
    "        final_responses = []\n",
    "        seen = set()\n",
    "    \n",
    "        for q in questions:\n",
    "            response = process_single_question(q)\n",
    "            if response:\n",
    "                for part in response.split(\"\\n---\\n\"):\n",
    "                    if part.strip() and part not in seen:\n",
    "                        final_responses.append(part.strip())\n",
    "                        seen.add(part.strip())\n",
    "    \n",
    "        if final_responses:\n",
    "            return \"\\n---\\n\".join(final_responses)\n",
    "        return \"🤔 مش فاهم عليك كويس، ممكن توضح أكتر؟\" if language == \"ar\" else \"🤔 I didn't quite understand. Could you clarify?\"\n",
    "\n",
    "\n",
    "def type_effect(text, delay=0):\n",
    "    for char in text:\n",
    "        sys.stdout.write(char)\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(delay)\n",
    "    print()  \n",
    "\n",
    "def welcome_message():\n",
    "    type_effect(\"🎉\\u202B أهلاً وسهلاً بيك في شات بوت Event Ease!\\u202C\")\n",
    "    type_effect(\"🎉 Welcome to the Event Ease Chatbot!\")\n",
    "    type_effect(\"📱 أنا هنا علشان أساعدك تخطط مناسبتك بسهولة – سواء فرح، خطوبة، عيد ميلاد أو غيرهم.\")\n",
    "    type_effect(\"📱 I'm here to help you easily plan your special events – weddings, engagements, birthdays, and more.\")\n",
    "    type_effect(\"💡 اسألني عن الحجز، الخدمات، تعديل أو إلغاء المناسبات، أو طريقة استخدام التطبيق.\")\n",
    "    type_effect(\"💡 Ask me about booking, services, editing or cancelling events, or how to use the app.\")\n",
    "    type_effect(\"🌐 تقدر تكتب بالعربي أو الإنجليزي.\")\n",
    "    type_effect(\"🌐 You can talk to me in Arabic or English.\")\n",
    "    print(\"___________________________\")\n",
    "welcome_message()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"📨 اكتب سؤالك (أو 'خروج' / 'انهاء' / 'باي' للخروج)\\n📨 Type your question (or 'exit' / 'bye' to quit): \")\n",
    "    arabic_goodbyes = [\"خروج\", \"انهاء\", \"باي\",\"سلام\",\"مع السلامة\"]\n",
    "    english_goodbyes = [\"bye\", \"exit\", \"goodbye\", \"see you\", \"farewell\"]\n",
    "    normalized_input = user_input.strip().lower()\n",
    "\n",
    "    if normalized_input in arabic_goodbyes:\n",
    "        type_effect(\"👋\\u202B مع السلامة! شكرًا لاستخدامك شات بوت Event Ease \\u202C.\") \n",
    "        break\n",
    "    elif normalized_input in english_goodbyes:\n",
    "        type_effect(\"👋 See you again! Thanks for using the Event Ease Chatbot. Have a great day!\")\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        response = get_response(user_input)\n",
    "        type_effect(\"🤖: \" + response)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431cea7-b694-4837-8f7d-4e7d73ecd06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
